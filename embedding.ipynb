{
 "cells": [],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "#coding:utf-8\n",
     "from gensim.models import Word2Vec\n",
     "from gensim.models import KeyedVectors\n",
     "import datetime\n",
     "import random\n",
     "\n",
     "# f=open(\"4-1版本1用户关系随机游走序列.txt\",\"r\")\n",
     "# sentences = [\n",
     "#     [\"3\",\"1\",\"3\",\"9\",\"3\",\"4\",\"3\",\"2\",\"3\"],\n",
     "#     [\"3\",\"1\",\"3\",\"5\",\"3\",\"8\",\"3\",\"2\",\"3\",\"6\",\"3\"],\n",
     "#     [\"3\",\"10\",\"3\",\"6\",\"3\",\"2\",\"3\",\"1\",\"3\"],\n",
     "#     [\"3\",\"9\",\"3\",\"1\",\"3\"],\n",
     "#     [\"3\",\"1\",\"3\"]\n",
     "# ]\n",
     "\n",
     "\n",
     "# sentences=[]\n",
     "# asum=0\n",
     "# for i in f:\n",
     "#     #去掉第一个地点编码，后面的为用户编码\n",
     "#     aaa=i.replace(\"\\n\",\"\").split(\",\")\n",
     "#     sentences.append(aaa)\n",
     "#     asum+=1\n",
     "#     # break\n",
     "#     ###################\n",
     "#     # if(asum==10000):\n",
     "#     #     break\n",
     "#     ##################\n",
     "# f.close()\n",
     "\n",
     "\n",
     "\n",
     "# for i in sentences:\n",
     "#     print(i)\n",
     "# raise()\n",
     "\n",
     "\n",
     "\n",
     "f=open(\"随机游走序列_100次_50步.txt\",\"r\",encoding=\"utf-8\")\n",
     "sentences=[]\n",
     "for i in f:\n",
     "    # print(i)\n",
     "    # raise()\n",
     "    a=i.strip().split(\",\")\n",
     "    # print(a)\n",
     "    sentences.append(a)\n",
     "f.close()\n",
     "# print(sentences)\n",
     "sentences=sentences\n",
     "print(len(sentences))\n",
     "\n",
     "\n",
     "# raise()\n",
     "\n",
     "\n",
     "# sentences = [\n",
     "#     [\"3\",\"1\",\"3\",\"9\",\"3\",\"4\",\"3\",\"2\",\"3\"],\n",
     "#     [\"3\",\"1\",\"3\",\"5\",\"3\",\"8\",\"3\",\"2\",\"3\",\"6\",\"3\"],\n",
     "#     [\"3\",\"10\",\"3\",\"6\",\"3\",\"2\",\"3\",\"1\",\"3\"],\n",
     "#     [\"3\",\"9\",\"3\",\"1\",\"3\"],\n",
     "#     [\"3\",\"1\",\"3\"]\n",
     "# ]\n",
     "\n",
     "# sentences=[\n",
     "#     [1,2,3,4,5,6,7,8,9,],\n",
     "#     [2,3,4,5,6,7,8,9,10],\n",
     "#     [3,4,5,6,7,8,9,10,11],\n",
     "#     [4,5,6,7,8,9,10,11,12],\n",
     "#     [5,6,7,8,9,10,11,12]\n",
     "#\n",
     "# ]\n",
     "\n",
     "# ###一个嵌入模型的实例\n",
     "# sentences=[]\n",
     "# for i in range(100000):\n",
     "#     lista=[]\n",
     "#     for j in range(i,i+10):\n",
     "#         lista.append(str(j))\n",
     "#     sentences.append(lista)\n",
     "# print(sentences)\n",
     "\n",
     "model_with_loss = Word2Vec(\n",
     "    min_count=0,\n",
     "    compute_loss=True,\n",
     "    hs=0,#1是分级softmax，0是负采样\n",
     "    sg=1,#训练算法，1是skip-gram，0是CBOW\n",
     "    seed=42,\n",
     "    size=100,workers=10,iter=1\n",
     ")\n",
     "\n",
     "\n",
     "model_with_loss.build_vocab(sentences)  # prepare the model vocabulary\n",
     "\n",
     "import tqdm\n",
     "for i in tqdm.tqdm(range(50)):\n",
     "    random.shuffle(sentences)\n",
     "    print(\"计算损失：\")\n",
     "# getting the training loss value\n",
     "    training_loss = model_with_loss.get_latest_training_loss()\n",
     "    print(training_loss)\n",
     "    print(\"开始培训：\")\n",
     "    model_with_loss.train(sentences=sentences,compute_loss=True,total_examples=model_with_loss.corpus_count,epochs=model_with_loss.iter)\n",
     "\n",
     "\n",
     "\n",
     "# raise()\n",
     "\n",
     "\n",
     "\n",
     "# print(\"开始训练\")\n",
     "# model = Word2Vec(min_count=1,size=100,workers=10)\n",
     "# model.build_vocab(sentences)  # prepare the model vocabulary\n",
     "# model.iter=100\n",
     "#\n",
     "# #模型迭代一遍所用的时间0:05:46.622112\n",
     "#\n",
     "# #打印一些相关参数\n",
     "# # print(model.iter)\n",
     "# # print(model.corpus_count)\n",
     "# # print(model.window)\n",
     "# # print(model.min_count)\n",
     "# # print(model.sg)\n",
     "# # print(model.alpha)\n",
     "# # print(model.min_alpha)\n",
     "#\n",
     "# start = datetime.datetime.now()\n",
     "# print(\"开始训练\")\n",
     "# model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n",
     "# print(\"结束训练\")\n",
     "# end = datetime.datetime.now()\n",
     "# print(end - start)\n",
     "\n",
     "\n",
     "######模型加载\n",
     "# model=Word2Vec.load(\"word2vec.model\")\n",
     "#####################\n",
     "\n",
     "#######模型求相似度\n",
     "print(model_with_loss.similarity(\"1\", \"2\"))\n",
     "print(model_with_loss.similarity(\"1\", \"45\"))\n",
     "# print(model.similarity('dog', 'say'))\n",
     "######################################\n",
     "\n",
     "######打印模型的嵌入的向量值\n",
     "# print(model[\"say\"])\n",
     "####################################\n",
     "\n",
     "###########模型保存\n",
     "model_with_loss.save(\"sum_relation_500.model\")  #模型保存\n",
     "model_with_loss.wv.save(\"sum_relation_500.kv\") #模型的嵌入向量文件保存\n",
     "######################\n",
     "\n",
     "\n",
     "# wv = KeyedVectors.load(\"wordvectors.kv\", mmap='r')\n",
     "# vector = wv['1']  # numpy vector of a word\n",
     "#\n",
     "# print(vector)\n",
     "# '''[-1.06593193e-02  1.01109548e-02 -7.43591134e-03 -1.29635669e-02\n",
     "#   1.48757352e-02 -6.94910530e-03 -7.58603495e-03  1.86305009e-02\n",
     "#  -1.39087271e-02  5.99567546e-03 -8.04566836e-04  3.17187817e-03\n",
     "#   7.25889811e-03  7.61491898e-03  2.50529544e-03  8.85979459e-03\n",
     "#   4.98266332e-03 -1.38026932e-02  1.21847745e-02  3.91440745e-03\n",
     "#   1.35238178e-03  2.69043865e-03  1.02743646e-02 -1.24960914e-02\n",
     "#   6.98336586e-03  1.07352082e-02 -6.44208957e-03  9.34791899e-07\n",
     "#  -9.54123773e-03  1.67856738e-02  1.25167414e-03 -6.10647677e-03\n",
     "#   4.99763992e-04  1.24679571e-02 -7.71110365e-03 -2.21710838e-02\n",
     "#   2.68112519e-03  6.57264935e-03 -4.69124410e-03  7.40040513e-03\n",
     "#  -5.40207187e-03 -1.17933275e-02  8.06967635e-03  1.02361618e-02\n",
     "#   1.23274531e-02 -5.51408203e-03 -6.43263198e-03  1.80766056e-03\n",
     "#  -1.33589818e-03 -3.47106741e-03  7.17991963e-03 -1.34332001e-03\n",
     "#  -7.33278552e-03  1.35073988e-02 -1.84385236e-02 -1.27615994e-02\n",
     "#  -1.30736809e-02 -3.46858520e-03  1.79111597e-03  2.82797194e-03\n",
     "#   7.64258066e-03 -7.70741049e-03  1.67404246e-02  1.52776400e-02]\n",
     "# '''\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "#整合用户的朋友关系和用户的签到关系#%%\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}