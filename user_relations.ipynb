{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "# id\tchecktime\tlocation\tjingweidu\n",
     "# 1\t2011-02-12 00:53:18\t1\t40.75051626137434,-73.9934992790222\n",
     "# 1\t2011-02-10 22:33:06\t2\t40.645089355976346,-73.7845230102539\n",
     "#\n",
     "import numpy as np\n",
     "\n",
     "# youzoucishu=50\n",
     "# youzoubushu=20\n",
     "# raise()\n",
     "f=open(\"my-CA-dataset-less10.txt\")\n",
     "f.readline()\n",
     "location_user={}\n",
     "user={}\n",
     "# raise()\n",
     "# a的形式为：['1', '2011-01-09 15:40:44', '5', '34.098,-118.328395']\n",
     "for i in f:\n",
     "    a=i.strip().split(\"\\t\")\n",
     "    try:\n",
     "        user[a[0]]\n",
     "    except:\n",
     "        user[a[0]]=1  #\n",
     "        continue\n",
     "    try:\n",
     "        location_user[int(a[2])]\n",
     "    except:\n",
     "        location_user[int(a[2])]=[]\n",
     "    if(int(a[0]) in location_user[int(a[2])]):\n",
     "        pass\n",
     "    else:\n",
     "        location_user[int(a[2])].append(int(a[0]))\n",
     "f.close()\n",
     "print(len(location_user))\n",
     "\n",
     "\n",
     "\n",
     "# 1\t2011-02-10 22:33:06\t2\t40.645089355976346,-73.7845230102539\n",
     "user_location_sum={}\n",
     "f=open(\"my-CA-dataset-less10.txt\")\n",
     "f.readline()\n",
     "for i in f:\n",
     "    a=i.strip().split(\"\\t\")\n",
     "    try:\n",
     "        user_location_sum[int(a[0])]\n",
     "    except:\n",
     "        user_location_sum[int(a[0])]={}\n",
     "    try:\n",
     "        user_location_sum[int(a[0])][int(a[2])]\n",
     "    except:\n",
     "        user_location_sum[int(a[0])][int(a[2])]=0\n",
     "    user_location_sum[int(a[0])][int(a[2])]+=1\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "aaa=0\n",
     "\n",
     "check_relation=np.zeros((len(user)+1,len(user)+1))\n",
     "for i in location_user:  #遍历所有地点，i表示一个地点\n",
     "    for j in location_user[i]:  #遍历当前地点的用户j\n",
     "        for k in location_user[i]:  #遍历当前地点的用户k\n",
     "            if(j==k):\n",
     "                pass\n",
     "            else:\n",
     "                min_sum=min([user_location_sum[j][i],user_location_sum[k][i]])\n",
     "                if(min_sum)>1:\n",
     "                    check_relation[j][k]+=min_sum\n",
     "                    aaa+=1\n",
     "                    # print(j,k)\n",
     "print(aaa)\n",
     "\n",
     "# import time\n",
     "# time.sleep(10000)\n",
     "\n",
     "# 709,6\n",
     "# 709,1219\n",
     "# 709,1220\n",
     "f=open(\"new_friendship_ca.txt\",\"r\",encoding=\"utf-8\")\n",
     "friend_relation=np.zeros((len(user)+1,len(user)+1))\n",
     "for i in f:\n",
     "    a=i.strip().split(\",\")\n",
     "    friend_relation[int(a[0])][int(a[1])]+=1\n",
     "f.close()\n",
     "\n",
     "hangmax=check_relation.sum(axis=1)\n",
     "for i,one_hangmax in zip([_ for _ in range(len(hangmax))],hangmax):\n",
     "    if(one_hangmax==0):\n",
     "        pass\n",
     "    else:\n",
     "        check_relation[i]=check_relation[i]/one_hangmax\n",
     "# check_relation=check_relation.cumsum(axis=1)\n",
     "\n",
     "hangmax=friend_relation.sum(axis=1)\n",
     "for i,one_hangmax in zip([_ for _ in range(len(hangmax))],hangmax):\n",
     "    if (one_hangmax == 0):\n",
     "        pass\n",
     "    else:\n",
     "        friend_relation[i] = friend_relation[i] / one_hangmax\n",
     "\n",
     "# friend_relation=check_relation.cumsum(axis=1)\n",
     "########## check_relation=check_relation.cumsum(axis=0)\n",
     "zong_relation=0.5*friend_relation+0.5*check_relation\n",
     "\n",
     "hangmax=zong_relation.sum(axis=1)\n",
     "for i,one_hangmax in zip([_ for _ in range(len(hangmax))],hangmax):\n",
     "    if (one_hangmax == 0):\n",
     "        pass\n",
     "    else:\n",
     "        zong_relation[i] = zong_relation[i] / one_hangmax\n",
     "zong_relation=zong_relation.cumsum(axis=1)\n",
     "\n",
     "\n",
     "#生成随机数列\n",
     "import random\n",
     "sentences=[]\n",
     "import tqdm\n",
     "\n",
     "\n",
     "print(\"正在生成嵌入数据：\")\n",
     "for i in tqdm.tqdm(range(1,len(zong_relation))):\n",
     "    # print(\"i\")\n",
     "    #生成50个的随机游走数列\n",
     "\n",
     "    for _ in range(500):  #随机游走次数\n",
     "        # print(_)\n",
     "        if (np.sum(zong_relation[i]) == 0):  # 当前用户和任何人都没有关系\n",
     "            print(\"没有边 \"+str(i))\n",
     "            break  #没有边和用户相邻\n",
     "        one_list=[]\n",
     "        one_list.append(i)\n",
     "        flag=i\n",
     "        while(len(one_list)!=50):  #50步长\n",
     "            # print(len(one_list))\n",
     "            one_random = random.random()  #生成0-1之间的数，不包括0和1\n",
     "            if(one_random==0):\n",
     "                import time\n",
     "                print(\"yes\")\n",
     "                time.sleep(10)\n",
     "                raise()\n",
     "\n",
     "            for j in range(1,len(zong_relation[flag])): #因为元素多个0，所以不用加1\n",
     "                # if(np.sum(flag)==0.):\n",
     "                #     raise()\n",
     "                # print(flag)\n",
     "                # print(\"__\")\n",
     "                # print(np.sum(zong_relation[1059]))\n",
     "                # print(np.sum(zong_relation[flag]))\n",
     "                # print(\"zong\" + str(zong_relation[flag][j]))\n",
     "                # print(one_random)\n",
     "                #\n",
     "                # print(j)\n",
     "                if(one_random<=zong_relation[flag][j]):\n",
     "                    # if(np.sum(zong_relation[j])==0):\n",
     "                    #     print(\"yes\")\n",
     "                    flag=j\n",
     "                    one_list.append(j)\n",
     "                    break  #找到了，继续找下一个元素\n",
     "        # print(one_list)\n",
     "        if(one_list==[]):\n",
     "            raise()\n",
     "            continue\n",
     "        sentences.append(one_list)\n",
     "\n",
     "fw=open(\"随机游走序列_500次_50步.txt\",\"w+\",encoding=\"utf-8\")\n",
     "for i in sentences:\n",
     "    fw.write(\",\".join([str(_) for _ in i])+str(\"\\n\"))\n",
     "fw.close()\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "#raise()  #由于生成随机游走序列太长，因此我把两个文件分开了\n",
     "#\n",
     "#\n",
     "#\n",
     "#\n",
     "#\n",
     "# from gensim.models import Word2Vec\n",
     "# from gensim.models import KeyedVectors\n",
     "# import datetime\n",
     "# import random\n",
     "#\n",
     "# # f=open(\"4-1版本1用户关系随机游走序列.txt\",\"r\")\n",
     "# # sentences = [\n",
     "# #     [\"3\",\"1\",\"3\",\"9\",\"3\",\"4\",\"3\",\"2\",\"3\"],\n",
     "# #     [\"3\",\"1\",\"3\",\"5\",\"3\",\"8\",\"3\",\"2\",\"3\",\"6\",\"3\"],\n",
     "# #     [\"3\",\"10\",\"3\",\"6\",\"3\",\"2\",\"3\",\"1\",\"3\"],\n",
     "# #     [\"3\",\"9\",\"3\",\"1\",\"3\"],\n",
     "# #     [\"3\",\"1\",\"3\"]\n",
     "# # ]\n",
     "#\n",
     "#\n",
     "# # sentences=[]\n",
     "# # asum=0\n",
     "# # for i in f:\n",
     "# #     #去掉第一个地点编码，后面的为用户编码\n",
     "# #     aaa=i.replace(\"\\n\",\"\").split(\",\")\n",
     "# #     sentences.append(aaa)\n",
     "# #     asum+=1\n",
     "# #     # break\n",
     "# #     ###################\n",
     "# #     # if(asum==10000):\n",
     "# #     #     break\n",
     "# #     ##################\n",
     "# # f.close()\n",
     "#\n",
     "#\n",
     "#\n",
     "# # for i in sentences:\n",
     "# #     print(i)\n",
     "# # raise()\n",
     "# random.shuffle(sentences)\n",
     "# print(\"开始训练\")\n",
     "# model = Word2Vec(min_count=1,size=100,workers=4)\n",
     "# model.build_vocab(sentences)  # prepare the model vocabulary\n",
     "# model.iter=1\n",
     "#\n",
     "# #模型迭代一遍所用的时间0:05:46.622112\n",
     "#\n",
     "# #打印一些相关参数\n",
     "# # print(model.iter)\n",
     "# # print(model.corpus_count)\n",
     "# # print(model.window)\n",
     "# # print(model.min_count)\n",
     "# # print(model.sg)\n",
     "# # print(model.alpha)\n",
     "# # print(model.min_alpha)\n",
     "#\n",
     "# start = datetime.datetime.now()\n",
     "# print(\"开始训练\")\n",
     "# model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n",
     "# print(\"结束训练\")\n",
     "# end = datetime.datetime.now()\n",
     "# print(end - start)\n",
     "#\n",
     "#\n",
     "# ######模型加载\n",
     "# # model=Word2Vec.load(\"word2vec.model\")\n",
     "# #####################\n",
     "#\n",
     "# #######模型求相似度\n",
     "# # print(model.similarity(\"1\", \"2\"))\n",
     "# # print(model.similarity(\"1\", \"3\"))\n",
     "# # print(model.similarity('dog', 'say'))\n",
     "# ######################################\n",
     "#\n",
     "# ######打印模型的嵌入的向量值\n",
     "# # print(model[\"say\"])\n",
     "# ####################################\n",
     "#\n",
     "# ###########模型保存\n",
     "# model.save(\"sum_relation_100.model\")  #模型保存\n",
     "# model.wv.save(\"sum_relation_100.kv\") #模型的嵌入向量文件保存\n",
     "# ######################\n",
     "\n",
     "\n",
     "# wv = KeyedVectors.load(\"wordvectors.kv\", mmap='r')\n",
     "# vector = wv['1']  # numpy vector of a word\n",
     "#\n",
     "# print(vector)\n",
     "# '''[-1.06593193e-02  1.01109548e-02 -7.43591134e-03 -1.29635669e-02\n",
     "#   1.48757352e-02 -6.94910530e-03 -7.58603495e-03  1.86305009e-02\n",
     "#  -1.39087271e-02  5.99567546e-03 -8.04566836e-04  3.17187817e-03\n",
     "#   7.25889811e-03  7.61491898e-03  2.50529544e-03  8.85979459e-03\n",
     "#   4.98266332e-03 -1.38026932e-02  1.21847745e-02  3.91440745e-03\n",
     "#   1.35238178e-03  2.69043865e-03  1.02743646e-02 -1.24960914e-02\n",
     "#   6.98336586e-03  1.07352082e-02 -6.44208957e-03  9.34791899e-07\n",
     "#  -9.54123773e-03  1.67856738e-02  1.25167414e-03 -6.10647677e-03\n",
     "#   4.99763992e-04  1.24679571e-02 -7.71110365e-03 -2.21710838e-02\n",
     "#   2.68112519e-03  6.57264935e-03 -4.69124410e-03  7.40040513e-03\n",
     "#  -5.40207187e-03 -1.17933275e-02  8.06967635e-03  1.02361618e-02\n",
     "#   1.23274531e-02 -5.51408203e-03 -6.43263198e-03  1.80766056e-03\n",
     "#  -1.33589818e-03 -3.47106741e-03  7.17991963e-03 -1.34332001e-03\n",
     "#  -7.33278552e-03  1.35073988e-02 -1.84385236e-02 -1.27615994e-02\n",
     "#  -1.30736809e-02 -3.46858520e-03  1.79111597e-03  2.82797194e-03\n",
     "#   7.64258066e-03 -7.70741049e-03  1.67404246e-02  1.52776400e-02]\n",
     "# '''\n",
     "#整合用户的朋友关系和用户的签到关系\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}